{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "773f0b05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " All libraries imported successfully\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import re\n",
    "from pathlib import Path\n",
    "from typing import Dict, List, Optional, Tuple\n",
    "from datetime import datetime\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Docling imports\n",
    "from docling.document_converter import DocumentConverter\n",
    "from docling.datamodel.base_models import InputFormat\n",
    "from docling.datamodel.pipeline_options import PdfPipelineOptions\n",
    "\n",
    "# LLM imports\n",
    "import ollama\n",
    "\n",
    "# Supabase\n",
    "from supabase import create_client, Client\n",
    "\n",
    "# Validation\n",
    "from jsonschema import validate, ValidationError\n",
    "\n",
    "print(\" All libraries imported successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0dbcc829",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon Nov 24 08:36:09 2025       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 575.57.08              Driver Version: 575.57.08      CUDA Version: 12.9     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  NVIDIA L4                      On  |   00000000:3C:00.0 Off |                    0 |\n",
      "| N/A   38C    P8             16W /   72W |       0MiB /  23034MiB |      0%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI              PID   Type   Process name                        GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|  No running processes found                                                             |\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cd92b45c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Configuration loaded\n",
      "  PDF Directory: C:\\Users\\samue\\Documents\\Work\\Code\\valuation_data_miner\\data\n",
      "  Output Directory: ./extracted_data\n",
      "  LLM Model: mistral\n"
     ]
    }
   ],
   "source": [
    "# Paths\n",
    "PDF_DIR = r\"C:\\Users\\samue\\Documents\\Work\\Code\\valuation_data_miner\\data\"\n",
    "OUTPUT_DIR = \"./extracted_data\"\n",
    "ERROR_LOG_DIR = \"./errors\"\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# dotenv_path = r\"C:\\Users\\samue\\Documents\\Work\\Code\\valuation_data_miner\\.env\"\n",
    "\n",
    "# with open(dotenv_path, \"r\") as f:\n",
    "#     for line in f:\n",
    "#         if line.strip() == \"\" or line.startswith(\"#\"):\n",
    "#             continue\n",
    "#         key, value = line.strip().split(\"=\", 1)\n",
    "#         os.environ[key] = value  # set environment variable\n",
    "\n",
    "\n",
    "\n",
    "load_dotenv() \n",
    "# Supabase credentials\n",
    "SUPABASE_URL = os.getenv(\"SUPABASE_URL\")\n",
    "SUPABASE_KEY = os.getenv(\"SUPABASE_KEY\")\n",
    "SUPABASE_TABLE = \"property_valuations\"\n",
    "\n",
    "\n",
    "\n",
    "# LLM settings\n",
    "LLM_MODEL = \"mistral\"\n",
    "LLM_TEMPERATURE = 0.1\n",
    "\n",
    "# Processing settings\n",
    "BATCH_SIZE = 5\n",
    "MAX_RETRIES = 2\n",
    "\n",
    "# Create directories\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "os.makedirs(ERROR_LOG_DIR, exist_ok=True)\n",
    "\n",
    "print(f\" Configuration loaded\")\n",
    "print(f\"  PDF Directory: {PDF_DIR}\")\n",
    "print(f\"  Output Directory: {OUTPUT_DIR}\")\n",
    "print(f\"  LLM Model: {LLM_MODEL}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "448357e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JSON schema defined\n"
     ]
    }
   ],
   "source": [
    "VALUATION_SCHEMA = {\n",
    "    \"type\": \"object\",\n",
    "    \"required\": [\"property_id\", \"valuation_report\", \"property_details\", \"valuations\"],\n",
    "    \"properties\": {\n",
    "        \"property_id\": {\"type\": \"string\"},\n",
    "        \"valuation_report\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"report_reference\": {\"type\": \"string\"},\n",
    "                \"valuer\": {\"type\": \"string\"},\n",
    "                \"valuers\": {\n",
    "                    \"type\": \"array\",\n",
    "                    \"items\": {\n",
    "                        \"type\": \"object\",\n",
    "                        \"properties\": {\n",
    "                            \"name\": {\"type\": \"string\"},\n",
    "                            \"qualification\": {\"type\": \"string\"}\n",
    "                        }\n",
    "                    }\n",
    "                },\n",
    "                \"inspection_date\": {\"type\": \"string\"},\n",
    "                \"report_date\": {\"type\": \"string\"},\n",
    "                \"client\": {\"type\": \"string\"},\n",
    "                \"client_address\": {\"type\": \"string\"},\n",
    "                \"purpose\": {\"type\": \"string\"}\n",
    "            }\n",
    "        },\n",
    "        \"property_details\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"apartment_number\": {\"type\": \"string\"},\n",
    "                \"block\": {\"type\": \"string\"},\n",
    "                \"floor\": {\"type\": \"string\"},\n",
    "                \"title_details\": {\"type\": \"object\"},\n",
    "                \"location\": {\"type\": \"object\"},\n",
    "                \"tenure\": {\"type\": \"object\"},\n",
    "                \"registered_proprietors\": {\"type\": \"array\"},\n",
    "                \"ownership_type\": {\"type\": \"string\"},\n",
    "                \"encumbrances\": {\"type\": \"string\"}\n",
    "            }\n",
    "        },\n",
    "        \"property_description\": {\"type\": \"object\"},\n",
    "        \"apartment_details\": {\"type\": \"object\"},\n",
    "        \"occupancy\": {\"type\": \"string\"},\n",
    "        \"condition\": {\"type\": \"string\"},\n",
    "        \"market_assessment\": {\"type\": \"object\"},\n",
    "        \"valuations\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"current_market_value\": {\n",
    "                    \"type\": \"object\",\n",
    "                    \"properties\": {\n",
    "                        \"amount\": {\"type\": \"number\"},\n",
    "                        \"currency\": {\"type\": \"string\"},\n",
    "                        \"amount_words\": {\"type\": \"string\"}\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "        },\n",
    "        \"valuation_methodology\": {\"type\": \"array\"},\n",
    "        \"lease_details\": {\"type\": \"object\"},\n",
    "        \"compliance\": {\"type\": \"object\"}\n",
    "    }\n",
    "}\n",
    "\n",
    "print(\"JSON schema defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a754d121",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Supabase credentials not configured\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from typing import Optional\n",
    "from supabase import create_client, Client\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# dotenv_path = r\"C:\\Users\\samue\\Documents\\Work\\Code\\valuation_data_miner\\.env\"\n",
    "\n",
    "# with open(dotenv_path, \"r\") as f:\n",
    "#     for line in f:\n",
    "#         if line.strip() == \"\" or line.startswith(\"#\"):\n",
    "#             continue\n",
    "#         key, value = line.strip().split(\"=\", 1)\n",
    "#         os.environ[key] = value  # set environment variable\n",
    "\n",
    "load_dotenv() \n",
    "\n",
    "\n",
    "def init_supabase() -> Optional[Client]:\n",
    "    \"\"\"Initialize Supabase client using environment variables\"\"\"\n",
    "    try:\n",
    "        supabase_url = os.getenv(\"SUPABASE_URL\")\n",
    "        supabase_key = os.getenv(\"SUPABASE_KEY\")\n",
    "\n",
    "        if not supabase_url or not supabase_key:\n",
    "            print(\"Supabase credentials not configured\")\n",
    "            return None\n",
    "\n",
    "        client = create_client(supabase_url, supabase_key)\n",
    "        print(\"Supabase client initialized\")\n",
    "        return client\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\" Failed to initialize Supabase: {e}\")\n",
    "        return None\n",
    "\n",
    "supabase_client = init_supabase()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "840c4e47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Hybrid Docling + Tesseract OCR processor loaded\n"
     ]
    }
   ],
   "source": [
    "import pytesseract\n",
    "from pdf2image import convert_from_path\n",
    "import tempfile\n",
    "import os\n",
    "\n",
    "def process_pdf_with_docling(pdf_path: str) -> str:\n",
    "    \"\"\"\n",
    "    Robust hybrid PDF extraction:\n",
    "    1. Extract text using Docling\n",
    "    2. Detect missing text\n",
    "    3. Run fallback Tesseract OCR for image-based pages\n",
    "    4. Merge into final extracted text\n",
    "    \"\"\"\n",
    "    try:\n",
    "        print(\"    → Processing PDF with Docling...\")\n",
    "\n",
    "        from docling.document_converter import DocumentConverter\n",
    "\n",
    "        # No options required for Docling 2.x\n",
    "        converter = DocumentConverter()\n",
    "        result = converter.convert(pdf_path)\n",
    "        doc = result.document\n",
    "\n",
    "        # ---------------------------\n",
    "        # (1) DOC TEXT EXTRACTION\n",
    "        # ---------------------------\n",
    "        markdown_text = doc.export_to_markdown() or \"\"\n",
    "        markdown_text = markdown_text.replace(\"<!-- image -->\", \"\").strip()\n",
    "\n",
    "        # Collect raw extracted text\n",
    "        extracted_raw = []\n",
    "        try:\n",
    "            for item in doc.iterate_items():\n",
    "                if hasattr(item, 'text') and item.text:\n",
    "                    t = item.text.strip()\n",
    "                    if t and t != \"<!-- image -->\":\n",
    "                        extracted_raw.append(t)\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        combined_docling_text = (markdown_text + \"\\n\" + \"\\n\".join(extracted_raw)).strip()\n",
    "\n",
    "        print(f\"    → Docling text extracted: {len(combined_docling_text)} chars\")\n",
    "\n",
    "        # ---------------------------\n",
    "        # (2) IF TEXT < THRESHOLD → RUN OCR\n",
    "        # ---------------------------\n",
    "        NEED_OCR = len(combined_docling_text) < 200  # You can adjust threshold\n",
    "\n",
    "        ocr_text = \"\"\n",
    "\n",
    "        if NEED_OCR:\n",
    "            print(\"    ⚠ Low text detected → Running Tesseract OCR fallback...\")\n",
    "            print(\"    → Converting PDF pages to images...\")\n",
    "\n",
    "            with tempfile.TemporaryDirectory() as tmpdir:\n",
    "                pages = convert_from_path(pdf_path, dpi=300, output_folder=tmpdir)\n",
    "\n",
    "                for idx, page in enumerate(pages):\n",
    "                    print(f\"        → OCR page {idx+1}/{len(pages)}\")\n",
    "                    page_text = pytesseract.image_to_string(page, lang=\"eng\")\n",
    "                    ocr_text += f\"\\n--- OCR Page {idx+1} ---\\n{page_text.strip()}\\n\"\n",
    "\n",
    "            print(f\"    → OCR extracted: {len(ocr_text)} chars\")\n",
    "\n",
    "        # ---------------------------\n",
    "        # (3) MERGE RESULTS\n",
    "        # ---------------------------\n",
    "        final_text = combined_docling_text\n",
    "        if NEED_OCR:\n",
    "            final_text = combined_docling_text + \"\\n\\n\" + ocr_text\n",
    "\n",
    "        # Clean formatting\n",
    "        import re\n",
    "        final_text = re.sub(r\"\\n{3,}\", \"\\n\\n\", final_text).strip()\n",
    "\n",
    "        print(f\"    → Final extracted text: {len(final_text)} chars\")\n",
    "\n",
    "        return final_text\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"    ✗ Docling failed: {str(e)}\")\n",
    "        raise Exception(f\"Docling processing failed: {str(e)}\")\n",
    "\n",
    "print(\"✓ Hybrid Docling + Tesseract OCR processor loaded\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a5d8e468",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Validation function defined\n"
     ]
    }
   ],
   "source": [
    "def validate_extracted_data(data: Dict) -> Tuple[bool, Optional[str]]:\n",
    "    \"\"\"\n",
    "    Validate extracted data against schema\n",
    "    Returns (is_valid, error_message)\n",
    "    \"\"\"\n",
    "    try:\n",
    "        validate(instance=data, schema=VALUATION_SCHEMA)\n",
    "        return True, None\n",
    "    except ValidationError as e:\n",
    "        return False, str(e)\n",
    "\n",
    "print(\" Validation function defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f1833f1",
   "metadata": {},
   "source": [
    "###  LLM Extraction with Mistral"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "70e86260",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Fixed LLM extraction function defined\n"
     ]
    }
   ],
   "source": [
    "def extract_with_llm(text_content: str, filename: str) -> Dict:\n",
    "    \"\"\"\n",
    "    Extract structured data from text using local Mistral model\n",
    "    FIXED: Better prompt and error handling\n",
    "    \"\"\"\n",
    "    \n",
    "    # Truncate content if too long\n",
    "    text_sample = text_content[:12000] if len(text_content) > 12000 else text_content\n",
    "    \n",
    "    # Simplified, more direct prompt\n",
    "    prompt = f\"\"\"You are extracting property valuation data. Return ONLY a JSON object, nothing else.\n",
    "\n",
    "Extract these fields from the document:\n",
    "- property_id\n",
    "- valuation_report (report_reference, valuer, inspection_date, report_date, client, purpose)\n",
    "- property_details (location, title_details, tenure)\n",
    "- valuations (current_market_value with amount and currency)\n",
    "- valuation_methodology (array of methods)\n",
    "\n",
    "Document text:\n",
    "{text_sample}\n",
    "\n",
    "Return ONLY the JSON object with this structure:\n",
    "{{\n",
    "  \"property_id\": \"\",\n",
    "  \"valuation_report\": {{}},\n",
    "  \"property_details\": {{}},\n",
    "  \"property_description\": {{}},\n",
    "  \"apartment_details\": {{}},\n",
    "  \"valuations\": {{}},\n",
    "  \"valuation_methodology\": []\n",
    "}}\"\"\"\n",
    "    \n",
    "    try:\n",
    "        print(f\"    → Sending to Mistral LLM...\")\n",
    "        \n",
    "        response = ollama.chat(\n",
    "            model=LLM_MODEL,\n",
    "            messages=[\n",
    "                {\"role\": \"user\", \"content\": prompt}\n",
    "            ],\n",
    "            options={\n",
    "                \"temperature\": 0.1,\n",
    "                \"num_predict\": 4096\n",
    "            }\n",
    "        )\n",
    "        \n",
    "        # Extract response\n",
    "        response_text = response['message']['content'].strip()\n",
    "        \n",
    "        # Debug: Save raw response\n",
    "        debug_file = os.path.join(ERROR_LOG_DIR, f\"{Path(filename).stem}_raw_response.txt\")\n",
    "        with open(debug_file, 'w', encoding='utf-8') as f:\n",
    "            f.write(f\"Raw LLM Response:\\n{response_text}\\n\\n\")\n",
    "            f.write(f\"Length: {len(response_text)} chars\\n\")\n",
    "        \n",
    "        print(f\"    → LLM returned {len(response_text)} characters\")\n",
    "        \n",
    "        # Check if response is empty\n",
    "        if not response_text or len(response_text) < 10:\n",
    "            raise Exception(f\"LLM returned empty or very short response: '{response_text}'\")\n",
    "        \n",
    "        # Clean response\n",
    "        if '```json' in response_text:\n",
    "            response_text = response_text.split('```json')[1].split('```')[0]\n",
    "        elif '```' in response_text:\n",
    "            response_text = response_text.split('```')[1].split('```')[0]\n",
    "        \n",
    "        response_text = response_text.strip()\n",
    "        \n",
    "        # Find JSON object if there's extra text\n",
    "        if not response_text.startswith('{'):\n",
    "            # Try to find JSON object in response\n",
    "            start = response_text.find('{')\n",
    "            end = response_text.rfind('}')\n",
    "            if start != -1 and end != -1:\n",
    "                response_text = response_text[start:end+1]\n",
    "        \n",
    "        # Try to parse JSON\n",
    "        try:\n",
    "            extracted_data = json.loads(response_text)\n",
    "        except json.JSONDecodeError as e:\n",
    "            # Save failed response for debugging\n",
    "            error_file = os.path.join(ERROR_LOG_DIR, f\"{Path(filename).stem}_json_error.txt\")\n",
    "            with open(error_file, 'w', encoding='utf-8') as f:\n",
    "                f.write(f\"JSON Parse Error: {str(e)}\\n\\n\")\n",
    "                f.write(f\"Cleaned Response:\\n{response_text}\\n\\n\")\n",
    "                f.write(f\"Original Response:\\n{response['message']['content']}\")\n",
    "            \n",
    "            # Return minimal valid structure instead of failing\n",
    "            print(f\"    ⚠ JSON parsing failed, creating minimal structure\")\n",
    "            extracted_data = {\n",
    "                \"property_id\": Path(filename).stem,\n",
    "                \"valuation_report\": {\n",
    "                    \"report_reference\": \"\",\n",
    "                    \"valuer\": \"\",\n",
    "                    \"inspection_date\": \"\",\n",
    "                    \"report_date\": \"\",\n",
    "                    \"client\": \"\",\n",
    "                    \"purpose\": \"\"\n",
    "                },\n",
    "                \"property_details\": {},\n",
    "                \"property_description\": {},\n",
    "                \"apartment_details\": {},\n",
    "                \"valuations\": {\n",
    "                    \"current_market_value\": {\n",
    "                        \"amount\": 0,\n",
    "                        \"currency\": \"KES\"\n",
    "                    }\n",
    "                },\n",
    "                \"valuation_methodology\": [],\n",
    "                \"_extraction_note\": \"LLM failed to return valid JSON, using template\"\n",
    "            }\n",
    "        \n",
    "        # Ensure property_id exists\n",
    "        if not extracted_data.get('property_id'):\n",
    "            extracted_data['property_id'] = Path(filename).stem\n",
    "        \n",
    "        print(f\"    → Extraction successful\")\n",
    "        return extracted_data\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"    ✗ LLM extraction error: {str(e)[:100]}\")\n",
    "        raise Exception(f\"LLM extraction failed: {str(e)}\")\n",
    "\n",
    "print(\"✓ Fixed LLM extraction function defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7eb3e427",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking Ollama status...\n",
      "✗ Ollama check failed: Failed to connect to Ollama. Please check that Ollama is downloaded, running and accessible. https://ollama.com/download\n",
      "\n",
      "Make sure Ollama is running:\n",
      "  1. Open terminal/command prompt\n",
      "  2. Run: ollama serve\n",
      "  3. Keep it running in background\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def check_ollama_status():\n",
    "    \"\"\"Verify Ollama is running and responsive\"\"\"\n",
    "    try:\n",
    "        print(\"Checking Ollama status...\")\n",
    "        response = ollama.list()\n",
    "        models = [m.model for m in response.models]\n",
    "        print(f\"✓ Ollama is running\")\n",
    "        print(f\"  Available models: {models}\")\n",
    "        \n",
    "        # Test a simple chat\n",
    "        print(\"\\nTesting Mistral model with simple query...\")\n",
    "        test_response = ollama.chat(\n",
    "            model='mistral',\n",
    "            messages=[{'role': 'user', 'content': 'Return only this JSON: {\"test\": \"success\"}'}],\n",
    "            options={'temperature': 0.1, 'num_predict': 100}\n",
    "        )\n",
    "        print(f\"✓ Test response: {test_response['message']['content'][:100]}\")\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(f\"✗ Ollama check failed: {e}\")\n",
    "        print(\"\\nMake sure Ollama is running:\")\n",
    "        print(\"  1. Open terminal/command prompt\")\n",
    "        print(\"  2. Run: ollama serve\")\n",
    "        print(\"  3. Keep it running in background\")\n",
    "        return False\n",
    "\n",
    "check_ollama_status()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9a0c1f74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No PDFs found\n",
      "\n",
      "============================================================\n",
      "READY TO TEST\n",
      "============================================================\n",
      "\n",
      "1. First run: test_single_pdf()\n",
      "2. If successful, run: results = process_all_pdfs()\n"
     ]
    }
   ],
   "source": [
    "def test_single_pdf():\n",
    "    \"\"\"Test processing one PDF to debug issues\"\"\"\n",
    "    pdf_files = list(Path(PDF_DIR).glob(\"*.pdf\"))\n",
    "    if not pdf_files:\n",
    "        print(\"No PDFs found\")\n",
    "        return\n",
    "    \n",
    "    test_file = pdf_files[0]\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Testing with: {test_file.name}\")\n",
    "    print(f\"{'='*60}\\n\")\n",
    "    \n",
    "    try:\n",
    "        # Step 1: Extract text\n",
    "        print(\"Step 1: Extracting text...\")\n",
    "        text = process_pdf_with_docling(str(test_file))\n",
    "        print(f\"✓ Extracted {len(text)} characters\")\n",
    "        print(f\"\\nFirst 500 chars:\\n{text[:500]}\\n\")\n",
    "        \n",
    "        # Step 2: LLM extraction\n",
    "        print(\"\\nStep 2: LLM extraction...\")\n",
    "        data = extract_with_llm(text, test_file.name)\n",
    "        print(f\"✓ Extracted data\")\n",
    "        print(json.dumps(data, indent=2)[:500])\n",
    "        \n",
    "        # Step 3: Validate\n",
    "        print(\"\\nStep 3: Validating...\")\n",
    "        is_valid, error = validate_extracted_data(data)\n",
    "        if is_valid:\n",
    "            print(\"✓ Validation passed\")\n",
    "        else:\n",
    "            print(f\"⚠ Validation warning: {error[:100]}\")\n",
    "        \n",
    "        # Step 4: Save\n",
    "        print(\"\\nStep 4: Saving...\")\n",
    "        output_file = os.path.join(OUTPUT_DIR, f\"{test_file.stem}.json\")\n",
    "        with open(output_file, 'w', encoding='utf-8') as f:\n",
    "            json.dump(data, f, indent=2, ensure_ascii=False)\n",
    "        print(f\"✓ Saved to {output_file}\")\n",
    "        \n",
    "        return True\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"\\n✗ Test failed: {str(e)}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        return False\n",
    "\n",
    "test_single_pdf()\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"READY TO TEST\")\n",
    "print(\"=\"*60)\n",
    "print(\"\\n1. First run: test_single_pdf()\")\n",
    "print(\"2. If successful, run: results = process_all_pdfs()\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2992b889",
   "metadata": {},
   "source": [
    "### Supabase upload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4e9b96f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Supabase upload function defined\n"
     ]
    }
   ],
   "source": [
    "def upload_to_supabase(client: Client, data: Dict, filename: str) -> bool:\n",
    "    \"\"\"\n",
    "    Upload extracted data to Supabase\n",
    "    Returns True if successful\n",
    "    \"\"\"\n",
    "    if client is None:\n",
    "        return False\n",
    "    \n",
    "    try:\n",
    "        # Add metadata\n",
    "        upload_data = data.copy()\n",
    "        upload_data['source_filename'] = filename\n",
    "        upload_data['processed_at'] = datetime.now().isoformat()\n",
    "        \n",
    "        # Insert into Supabase\n",
    "        response = client.table(SUPABASE_TABLE).insert(upload_data).execute()\n",
    "        \n",
    "        return True\n",
    "        \n",
    "    except Exception as e:\n",
    "        raise Exception(f\"Supabase upload failed: {str(e)}\")\n",
    "\n",
    "print(\"Supabase upload function defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71a98331",
   "metadata": {},
   "source": [
    "### Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "94c93479",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Main pipeline function defined\n"
     ]
    }
   ],
   "source": [
    "def process_single_pdf(pdf_path: str, filename: str) -> Dict:\n",
    "    \"\"\"\n",
    "    Process a single PDF through the entire pipeline\n",
    "    Returns result dictionary with status\n",
    "    \"\"\"\n",
    "    result = {\n",
    "        'filename': filename,\n",
    "        'success': False,\n",
    "        'stage': None,\n",
    "        'error': None,\n",
    "        'data': None\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        # Stage 1: Docling OCR\n",
    "        result['stage'] = 'docling'\n",
    "        text_content = process_pdf_with_docling(pdf_path)\n",
    "        \n",
    "        # Stage 2: LLM Extraction\n",
    "        result['stage'] = 'extraction'\n",
    "        extracted_data = extract_with_llm(text_content, filename)\n",
    "        \n",
    "        # Stage 3: Validation\n",
    "        result['stage'] = 'validation'\n",
    "        is_valid, validation_error = validate_extracted_data(extracted_data)\n",
    "        \n",
    "        if not is_valid:\n",
    "            result['error'] = f\"Validation failed: {validation_error}\"\n",
    "        \n",
    "        result['data'] = extracted_data\n",
    "        \n",
    "        # Stage 4: Save locally\n",
    "        result['stage'] = 'saving'\n",
    "        output_file = os.path.join(OUTPUT_DIR, f\"{Path(filename).stem}.json\")\n",
    "        with open(output_file, 'w', encoding='utf-8') as f:\n",
    "            json.dump(extracted_data, f, indent=2, ensure_ascii=False)\n",
    "        \n",
    "        # Stage 5: Upload to Supabase\n",
    "        if supabase_client and is_valid:\n",
    "            result['stage'] = 'upload'\n",
    "            upload_to_supabase(supabase_client, extracted_data, filename)\n",
    "        \n",
    "        result['success'] = True\n",
    "        result['stage'] = 'complete'\n",
    "        \n",
    "    except Exception as e:\n",
    "        result['error'] = str(e)\n",
    "        \n",
    "        # Log error\n",
    "        error_file = os.path.join(ERROR_LOG_DIR, f\"{Path(filename).stem}_error.txt\")\n",
    "        with open(error_file, 'w') as f:\n",
    "            f.write(f\"Stage: {result['stage']}\\n\")\n",
    "            f.write(f\"Error: {result['error']}\\n\")\n",
    "    \n",
    "    return result\n",
    "\n",
    "print(\" Main pipeline function defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ad814a2",
   "metadata": {},
   "source": [
    "### Batch processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "59e32a84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch processing function defined\n"
     ]
    }
   ],
   "source": [
    "def process_all_pdfs():\n",
    "    \"\"\"\n",
    "    Process all PDFs in the configured directory\n",
    "    \"\"\"\n",
    "    # Get all PDF files\n",
    "    pdf_files = list(Path(PDF_DIR).glob(\"*.pdf\"))\n",
    "    \n",
    "    if not pdf_files:\n",
    "        print(f\"✗ No PDF files found in {PDF_DIR}\")\n",
    "        return []\n",
    "    \n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Found {len(pdf_files)} PDF files to process\")\n",
    "    print(f\"{'='*60}\\n\")\n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    # Process each PDF\n",
    "    for pdf_file in tqdm(pdf_files, desc=\"Processing PDFs\"):\n",
    "        print(f\"\\n[{pdf_file.name}]\")\n",
    "        result = process_single_pdf(str(pdf_file), pdf_file.name)\n",
    "        results.append(result)\n",
    "        \n",
    "        if result['success']:\n",
    "            print(f\"  ✓ Successfully processed\")\n",
    "        else:\n",
    "            print(f\"  ✗ Failed at stage '{result['stage']}': {result['error']}\")\n",
    "    \n",
    "    # Summary\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(\"PROCESSING SUMMARY\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    successful = sum(1 for r in results if r['success'])\n",
    "    failed = len(results) - successful\n",
    "    \n",
    "    print(f\"Total PDFs: {len(results)}\")\n",
    "    print(f\"Successful: {successful}\")\n",
    "    print(f\"Failed: {failed}\")\n",
    "    print(f\"\\nOutput saved to: {OUTPUT_DIR}\")\n",
    "    if failed > 0:\n",
    "        print(f\"Error logs saved to: {ERROR_LOG_DIR}\")\n",
    "    \n",
    "    # Save summary report\n",
    "    summary_file = os.path.join(OUTPUT_DIR, \"processing_summary.json\")\n",
    "    with open(summary_file, 'w') as f:\n",
    "        json.dump({\n",
    "            'timestamp': datetime.now().isoformat(),\n",
    "            'total': len(results),\n",
    "            'successful': successful,\n",
    "            'failed': failed,\n",
    "            'results': results\n",
    "        }, f, indent=2)\n",
    "    \n",
    "    return results\n",
    "\n",
    "print(\"Batch processing function defined\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "03c33d83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 0 PDF files in C:\\Users\\samue\\Documents\\Work\\Code\\valuation_data_miner\\data\n",
      "\n",
      "WARNING: No PDF files found!\n",
      "Please check that PDFs exist in: C:\\Users\\samue\\Documents\\Work\\Code\\valuation_data_miner\\data\n"
     ]
    }
   ],
   "source": [
    "pdf_count = len(list(Path(PDF_DIR).glob(\"*.pdf\")))\n",
    "print(f\"Found {pdf_count} PDF files in {PDF_DIR}\")\n",
    "\n",
    "if pdf_count == 0:\n",
    "    print(f\"\\nWARNING: No PDF files found!\")\n",
    "    print(f\"Please check that PDFs exist in: {PDF_DIR}\")\n",
    "else:\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"STARTING PDF PROCESSING PIPELINE\")\n",
    "    print(\"=\"*60)\n",
    "    print(\"\\nThis will:\")\n",
    "    print(\"1. Extract text from PDFs using Docling OCR\")\n",
    "    print(\"2. Extract structured data using Mistral LLM\")\n",
    "    print(\"3. Validate against JSON schema\")\n",
    "    print(\"4. Save to local JSON files\")\n",
    "    print(\"5. Upload to Supabase (if configured)\")\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    \n",
    "    # RUN THE PIPELINE\n",
    "    results = process_all_pdfs()\n",
    "    \n",
    "    print(\"\\nPROCESSING COMPLETE!\")\n",
    "    print(f\"Check results in: {OUTPUT_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f853339f",
   "metadata": {},
   "source": [
    "### Ollama setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ec296810",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✗ Could not check Ollama models: Failed to connect to Ollama. Please check that Ollama is downloaded, running and accessible. https://ollama.com/download\n",
      "Make sure Ollama is running (run 'ollama serve' in terminal')\n"
     ]
    }
   ],
   "source": [
    "import ollama\n",
    "\n",
    "try:\n",
    "    response = ollama.list()\n",
    "    print(\"RAW MODEL RESPONSE:\", response)\n",
    "\n",
    "    models = response.models  # this is a list of Model objects\n",
    "    model_names = [m.model for m in models]  # use .model attribute\n",
    "\n",
    "    print(\"Detected models:\", model_names)\n",
    "\n",
    "    if LLM_MODEL not in model_names and f\"{LLM_MODEL}:latest\" not in model_names:\n",
    "        print(f\"⚠ Warning: Model '{LLM_MODEL}' not found in Ollama\")\n",
    "        print(f\"Available models: {model_names}\")\n",
    "        print(\"\\nTo install Mistral, run in terminal: ollama pull mistral\")\n",
    "    else:\n",
    "        print(f\"✓ Model '{LLM_MODEL}' is available\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"✗ Could not check Ollama models: {e}\")\n",
    "    print(\"Make sure Ollama is running (run 'ollama serve' in terminal')\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a22b684e",
   "metadata": {},
   "source": [
    "### View sample results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "beaf38b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No output files found yet\n"
     ]
    }
   ],
   "source": [
    "json_files = list(Path(OUTPUT_DIR).glob(\"*.json\"))\n",
    "json_files = [f for f in json_files if f.name != \"processing_summary.json\"]\n",
    "\n",
    "if json_files:\n",
    "    sample_file = json_files[0]\n",
    "    print(f\"Sample output from: {sample_file.name}\\n\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    with open(sample_file, 'r') as f:\n",
    "        sample_data = json.load(f)\n",
    "    \n",
    "    print(json.dumps(sample_data, indent=2))\n",
    "else:\n",
    "    print(\"No output files found yet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73bdd38f",
   "metadata": {},
   "source": [
    "### reprocess failed files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d6aeac88",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reprocess_failed(previous_results):\n",
    "    \"\"\"Reprocess only the failed PDFs\"\"\"\n",
    "    failed_files = [r['filename'] for r in previous_results if not r['success']]\n",
    "    \n",
    "    if not failed_files:\n",
    "        print(\"No failed files to reprocess\")\n",
    "        return []\n",
    "    \n",
    "    print(f\"Reprocessing {len(failed_files)} failed PDFs...\")\n",
    "    \n",
    "    retry_results = []\n",
    "    for filename in tqdm(failed_files, desc=\"Retrying\"):\n",
    "        pdf_path = os.path.join(PDF_DIR, filename)\n",
    "        result = process_single_pdf(pdf_path, filename)\n",
    "        retry_results.append(result)\n",
    "        \n",
    "        if result['success']:\n",
    "            print(f\"  ✓ {filename} - Success on retry\")\n",
    "        else:\n",
    "            print(f\"  ✗ {filename} - Failed again\")\n",
    "    \n",
    "    return retry_results\n",
    "\n",
    "if 'results' in locals() and results:\n",
    "    retry_results = reprocess_failed(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5c39a4e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Supabase client not initialized\n"
     ]
    }
   ],
   "source": [
    "def query_supabase_sample():\n",
    "    \"\"\"Query and display sample data from Supabase\"\"\"\n",
    "    if supabase_client is None:\n",
    "        print(\"Supabase client not initialized\")\n",
    "        return\n",
    "    \n",
    "    try:\n",
    "        response = supabase_client.table(SUPABASE_TABLE).select(\"*\").limit(5).execute()\n",
    "        print(f\"Sample records from Supabase ({SUPABASE_TABLE}):\\n\")\n",
    "        print(json.dumps(response.data, indent=2))\n",
    "    except Exception as e:\n",
    "        print(f\"Error querying Supabase: {e}\")\n",
    "\n",
    "query_supabase_sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "20e43462",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_results(results):\n",
    "    \"\"\"Analyze processing results\"\"\"\n",
    "    if not results:\n",
    "        print(\"No results to analyze\")\n",
    "        return\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"DETAILED ANALYSIS\")\n",
    "    print(\"=\"*60 + \"\\n\")\n",
    "    \n",
    "    # Stage failures\n",
    "    stage_failures = {}\n",
    "    for r in results:\n",
    "        if not r['success'] and r['stage']:\n",
    "            stage_failures[r['stage']] = stage_failures.get(r['stage'], 0) + 1\n",
    "    \n",
    "    if stage_failures:\n",
    "        print(\"Failures by stage:\")\n",
    "        for stage, count in sorted(stage_failures.items(), key=lambda x: x[1], reverse=True):\n",
    "            print(f\"  {stage}: {count}\")\n",
    "    \n",
    "    # Validation stats\n",
    "    validation_issues = [r for r in results if r['error'] and 'Validation' in r['error']]\n",
    "    print(f\"\\nValidation issues: {len(validation_issues)}\")\n",
    "    \n",
    "    # Success rate\n",
    "    success_rate = (sum(1 for r in results if r['success']) / len(results)) * 100\n",
    "    print(f\"\\nSuccess rate: {success_rate:.1f}%\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "\n",
    "if 'results' in locals() and results:\n",
    "    analyze_results(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c05b1191",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No JSON files to export\n"
     ]
    }
   ],
   "source": [
    "def export_to_csv():\n",
    "    \"\"\"Export extracted valuations to CSV for easy viewing\"\"\"\n",
    "    import csv\n",
    "    \n",
    "    json_files = list(Path(OUTPUT_DIR).glob(\"*.json\"))\n",
    "    json_files = [f for f in json_files if f.name != \"processing_summary.json\"]\n",
    "    \n",
    "    if not json_files:\n",
    "        print(\"No JSON files to export\")\n",
    "        return\n",
    "    \n",
    "    csv_path = os.path.join(OUTPUT_DIR, \"valuations_summary.csv\")\n",
    "    \n",
    "    with open(csv_path, 'w', newline='', encoding='utf-8') as csvfile:\n",
    "        fieldnames = ['property_id', 'client', 'location', 'valuation_amount', \n",
    "                     'currency', 'report_date', 'source_file']\n",
    "        writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "        \n",
    "        writer.writeheader()\n",
    "        \n",
    "        for json_file in json_files:\n",
    "            with open(json_file, 'r') as f:\n",
    "                data = json.load(f)\n",
    "            \n",
    "            row = {\n",
    "                'property_id': data.get('property_id', ''),\n",
    "                'client': data.get('valuation_report', {}).get('client', ''),\n",
    "                'location': data.get('property_details', {}).get('location', {}).get('area', ''),\n",
    "                'valuation_amount': data.get('valuations', {}).get('current_market_value', {}).get('amount', ''),\n",
    "                'currency': data.get('valuations', {}).get('current_market_value', {}).get('currency', ''),\n",
    "                'report_date': data.get('valuation_report', {}).get('report_date', ''),\n",
    "                'source_file': json_file.name\n",
    "            }\n",
    "            \n",
    "            writer.writerow(row)\n",
    "    \n",
    "    print(f\"✓ CSV exported to: {csv_path}\")\n",
    "\n",
    "export_to_csv()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
